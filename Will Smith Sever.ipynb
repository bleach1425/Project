{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n    ## 流程 = 語音接收-->儲存-->mfcc轉換-->判別--回傳結果 ##\\n    1. 音檔必須大於10s的版本\\n    2. 訓練資料:train_v7.json\\n    3. 權重:model_version_v7.h5\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "    ## 流程 = 語音接收-->儲存-->mfcc轉換-->判別--回傳結果 ##\n",
    "    1. 音檔必須大於10s的版本\n",
    "    2. 訓練資料:train_v7.json\n",
    "    3. 權重:model_version_v7.h5\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pc06\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\errors.py:149: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import struct\n",
    "import base64\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import wave\n",
    "from flask import Flask, jsonify, request\n",
    "from flask_cors import cross_origin\n",
    "from keras.models import load_model\n",
    "import speech_recognition as sr\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import speech_recognition as sr\n",
    "from googletrans import Translator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw\n",
    "def oscillogram_spectrum():\n",
    "    \"\"\"\n",
    "    画出音频文件audio_path的声波图和频谱图\n",
    "    :param audio_path:音频文件路径\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 读取wav文件\n",
    "    filename = \"./audio.wav\"\n",
    "    wavefile = wave.open(filename, 'r')  # open for writing\n",
    "    # 读取wav文件的四种信息的函数。numframes表示一共读取了几个frames。\n",
    "    nchannels = wavefile.getnchannels()\n",
    "    sample_width = wavefile.getsampwidth()\n",
    "    framerate = wavefile.getframerate()\n",
    "    numframes = wavefile.getnframes()\n",
    "    y = np.zeros(numframes)\n",
    "\n",
    "    for index, i in enumerate(range(numframes)):\n",
    "        val = wavefile.readframes(1)\n",
    "        left = val[0:2]\n",
    "        # right = val[2:4]\n",
    "        v = struct.unpack('h', left)[0]\n",
    "        # print(\"v\", v)\n",
    "        y[i] = v\n",
    "    # framerate就是声音的采用率，文件初读取的值。\n",
    "    Fs = framerate\n",
    "    time = np.arange(0, numframes) * (1.0 / framerate)\n",
    "    feature=[]\n",
    "    feature_y=[]\n",
    "    dict_={\n",
    "        \"y\":y\n",
    "    }\n",
    "\n",
    "    for i, x in enumerate(time):\n",
    "        if y[i]>=500 or y[i]<=-500:\n",
    "            feature.append(x)\n",
    "            feature_y.append(y[i])\n",
    "\n",
    "\n",
    "    time_cut = round(numframes/4)\n",
    "    new_time_cut = [word for word in time if word != 0.0]\n",
    "    # print(new_time_cut)\n",
    "    feature = np.array(feature)\n",
    "    feature_y = np.array(feature_y)\n",
    "\n",
    "#     time1 = time[ :time_cut]\n",
    "#     time2 = time[time_cut : time_cut*2]\n",
    "#     time3 = time[time_cut*2 : time_cut*3]\n",
    "#     time4 = time[time_cut*3:]\n",
    "\n",
    "    # 显示时域图(波形图)\n",
    "    # plt.subplot(2,2,1)\n",
    "    plt.subplot(1,1,1)\n",
    "    a,= plt.plot(feature, feature_y, color='r')\n",
    "    # plt.subplot(2,2,2)\n",
    "    # plt.subplot(1,1,1)\n",
    "    b, = plt.plot(time, y)\n",
    "\n",
    "    plt.legend([a , b], [\"Teacher Voice\", \"Your Voice\"])\n",
    "    # plt.subplot(1,1,1)\n",
    "    # plt.subplot(2,2,1)\n",
    "    # plt.plot(time1, y[ :time_cut])\n",
    "    #\n",
    "    # plt.subplot(2, 2, 2)\n",
    "    # plt.plot(time2, y[time_cut : time_cut*2])\n",
    "    #\n",
    "    # plt.subplot(2, 2, 3)\n",
    "    # plt.plot(time3, y[time_cut*2 : time_cut*3])\n",
    "    #\n",
    "    # plt.subplot(2, 2, 4)\n",
    "    # plt.plot(time4, y[time_cut*3:])\n",
    "    \n",
    "    # 显示频域图(频谱图)\n",
    "    # plt.subplot(2,2,3)\n",
    "    # plt.specgram(y, NFFT=1024, Fs=Fs, noverlap=900)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.5, wspace=0.3)\n",
    "    plt.rcParams['savefig.dpi'] = 100\n",
    "    plt.rcParams['figure.dpi'] = 100\n",
    "    plt.ylabel('amplitude(db)',fontsize=10)\n",
    "    plt.xlabel('Time(s)',fontsize=10)\n",
    "    plt.savefig('./audio.png')\n",
    "    plt.show()\n",
    "    \n",
    "def Bargraph():\n",
    "    plt.plot(point_list, color=\"b\", linewidth=3)\n",
    "    plt.figsize=(12,8)\n",
    "    plt.title('Mr. XXX Growth Record',fontsize=20)\n",
    "    plt.xlabel('date',fontsize=12)\n",
    "    plt.ylabel('point',fontsize=12)\n",
    "    plt.xtick(fontsize=10)\n",
    "    plt.ytick(fontsize=10)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "level1=0\n",
    "level2=0\n",
    "level3=0\n",
    "level4=0\n",
    "level5=0\n",
    "\n",
    "def check_your_audio():\n",
    "    # 读取wav文件\n",
    "    filename = \"./audio.wav\"\n",
    "    wavefile = wave.open(filename, 'r')  # open for writing\n",
    "    # 读取wav文件的四种信息的函数。numframes表示一共读取了几个frames。\n",
    "    nchannels = wavefile.getnchannels()\n",
    "    sample_width = wavefile.getsampwidth()\n",
    "    framerate = wavefile.getframerate()\n",
    "    numframes = wavefile.getnframes()\n",
    "\n",
    "    y = np.zeros(numframes)\n",
    "    return numframes, y, wavefile\n",
    "            \n",
    "def load_data_test(data_path):\n",
    "    with open(data_path, \"r\",encoding=\"utf-8\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "    X = X[..., np.newaxis]\n",
    "    X = X[:,np.newaxis]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def pika(point):\n",
    "    if point >= 0 and point <=50:\n",
    "        return \"你離偶像還有一段距離哦!\"\n",
    "    elif point >= 50 and point <=100:\n",
    "        return \"哇, 跟威爾史密斯的聲音越來越像囉!\"\n",
    "\n",
    "\n",
    "def prediction(X, model_load):\n",
    "    score_sum=0\n",
    "    name_score=0\n",
    "    point_list=[]\n",
    "    for i, pre in enumerate(X):\n",
    "        prediction = model_load.predict(pre)\n",
    "        # print(\"prediction: \",prediction)\n",
    "        predictied_index = np.argmax(prediction, axis=1)\n",
    "        if int(predictied_index[0]) == 0:\n",
    "            predictied_index = np.argmin(prediction, axis=1)\n",
    "        score = (prediction[0][predictied_index])\n",
    "        # # print(i, predictied_index)\n",
    "#         print(\"prediction: \", prediction)\n",
    "        score_sum += score\n",
    "        if (i+1)%4==0:\n",
    "            print((score_sum/4)*100)\n",
    "            response = int((score_sum/4)*100)\n",
    "            point_list.append(response)\n",
    "            score_sum=0\n",
    "            name_score+=1\n",
    "    return pika(response)\n",
    "\n",
    "# PATH\n",
    "def get_mfcc():\n",
    "    data = {\n",
    "    \"name\":[],\n",
    "    \"labels\": [],\n",
    "    \"mfcc\": []\n",
    "    }\n",
    "    JSON_PATH = \"./audio.json\"\n",
    "    SAMPLE_RATE = 22050\n",
    "    TRACK_DURATION = 10  # measured in seconds   ###### 10 、16秒兩個版本 ######\n",
    "    SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
    "\n",
    "    # PARAMS\n",
    "    num_mfcc=13\n",
    "    n_fft=2048\n",
    "    hop_length=512\n",
    "    num_segments=4\n",
    "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "\n",
    "    # user files transform\n",
    "    file = \"./audio.wav\"\n",
    "\n",
    "    signal, sample_rate = librosa.load(file, sr=SAMPLE_RATE)\n",
    "\n",
    "    # process all segments of audio file\n",
    "    for id, d in enumerate(range(num_segments)):\n",
    "        # calculate start and finish sample for current segment\n",
    "        start = samples_per_segment * d\n",
    "        finish = start + samples_per_segment\n",
    "\n",
    "        # extract mfcc\n",
    "        mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
    "                                    hop_length=hop_length)\n",
    "        mfcc = mfcc.T\n",
    "\n",
    "        # store only mfcc feature with expected number of vectors\n",
    "        if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "            # print(mfcc)\n",
    "            name = file.split(\"./\")[1].split(\".wav\")[0]\n",
    "            if (id+1)%4 == 0:\n",
    "                data[\"name\"].append(name)\n",
    "            data[\"mfcc\"].append(mfcc.tolist())\n",
    "            data[\"labels\"].append(0)\n",
    "\n",
    "    with open(\"audio.json\", \"w\",encoding=\"utf-8\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "\n",
    "    return \"MFCC OK\"\n",
    "\n",
    "def back_img():\n",
    "    img_path=\"./audio.png\"\n",
    "    with open(img_path, 'rb') as img_f:\n",
    "        img_stream = img_f.read()\n",
    "        img_stream = base64.b64encode(img_stream)\n",
    "    return img_stream\n",
    "\n",
    "def plot_picture():\n",
    "    plt.plot(point_list, color=\"b\", linewidth=3)\n",
    "    plt.figsize=(12,8)\n",
    "    plt.title('Mr. XXX Growth Record',fontsize=20)\n",
    "    plt.xlabel('date',fontsize=12)\n",
    "    plt.ylabel('point',fontsize=12)\n",
    "    plt.xtick(fontsize=10)\n",
    "    plt.ytick(fontsize=10)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "@app.route('/file', methods=['GET', \"POST\"])\n",
    "@cross_origin()\n",
    "def files():\n",
    "    normal_sound=0\n",
    "    too_low_sound=0\n",
    "    file = request.files['file']\n",
    "    file.save('./audio.wav')\n",
    "    numframes, y, wavefile = check_your_audio()\n",
    "    for index, i in enumerate(range(numframes)):\n",
    "        val = wavefile.readframes(1)\n",
    "        left = val[0:2]\n",
    "        # right = val[2:4]\n",
    "        v = struct.unpack('h', left)[0]\n",
    "        y[i] = v\n",
    "        if y[i] >=500 or y[i]<=-500:\n",
    "            normal_sound+=1\n",
    "        else:\n",
    "            too_low_sound+=1\n",
    "    if normal_sound >= int(numframes*0.3):\n",
    "        print('音量正常', normal_sound, too_low_sound)\n",
    "#         response_dict={\n",
    "#             \"response\":\"Voice OK\"\n",
    "#         }\n",
    "#         response = json.dumps(response_dict)\n",
    "#         return response\n",
    "    else:\n",
    "        print('音量太小', normal_sound, too_low_sound)\n",
    "        response_dict={\n",
    "            \"response\":\"Your voice is too low\"\n",
    "        }\n",
    "        response = json.dumps(response_dict)\n",
    "        return response\n",
    "    get_mfcc()\n",
    "    TEST_PATH = \"./audio.json\"\n",
    "    X, y = load_data_test(TEST_PATH)\n",
    "    # 16s \"model_version_v7.h5\"\n",
    "    model_load = load_model(\"model/Will Smith 0.0403 - 0.975.h5\")\n",
    "    response = prediction(X, model_load)\n",
    "    print(response)\n",
    "    # picture\n",
    "    oscillogram_spectrum()\n",
    "    Bargraph()\n",
    "    picture = back_img()\n",
    "    re = {\n",
    "        \"response\" : response,\n",
    "        \"picture\" : picture.decode('utf-8')\n",
    "    }\n",
    "    re = json.dumps(re)\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5003/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0',port = 5003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
