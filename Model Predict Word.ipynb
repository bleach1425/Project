{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pc06\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import librosa\n",
    "import speech_recognition as sr\n",
    "from flask import Flask, jsonify, request\n",
    "from flask_cors import cross_origin\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "model = FastText.load_fasttext_format('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level1=0\n",
    "level2=0\n",
    "level3=0\n",
    "level4=0\n",
    "level5=0\n",
    "\n",
    "# All_file = glob.glob('C:/Users/PC06/Desktop/語音進度/will smith/0/*')\n",
    "file_name = []\n",
    "\n",
    "def load_data_test(data_path):\n",
    "    with open(data_path, \"r\",encoding=\"utf-8\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "    X = X[..., np.newaxis]\n",
    "    X = X[:,np.newaxis]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def score_(point):\n",
    "    global level1, level2, level3, level4, level5\n",
    "    if point >=0 and point <=20:\n",
    "        level1+=1\n",
    "        return ('你的美式口音還需要多加強')\n",
    "    elif point >=21 and point <=40:\n",
    "        level2+=1\n",
    "        return ('你的美式口音有抓到一點訣竅，但還有很多細節沒有到位，多多練習會更好哦')\n",
    "    elif point >=41 and point <=60:\n",
    "        level3+=1\n",
    "        return ('你的美式口音表現很不錯, 但一些口音細節還需要加強')\n",
    "    elif point >=61 and point <=80:\n",
    "        level4+=1\n",
    "        return ('你的美式口音整理表現得很好、細節也有到位, 多練習就完美囉 ')\n",
    "    elif point >=81 and point <=100:\n",
    "        level5+=1\n",
    "        return ('你的美式口英非常標準, 恭喜你')\n",
    "    \n",
    "def pika(point):\n",
    "    if point >= 0 and point <=50:\n",
    "        return \"你離偶像還有一段距離哦!\"\n",
    "    elif point >= 50 and point <=100:\n",
    "        return \"哇, 跟李奧納多的聲音越來越像囉!\"\n",
    "\n",
    "def prediction(X, model_load):\n",
    "    score_sum=0\n",
    "    name_score=0\n",
    "    point_list=[]\n",
    "    for i, pre in enumerate(X):\n",
    "        prediction = model_load.predict(pre)\n",
    "        # print(\"prediction: \",prediction)\n",
    "        predictied_index = np.argmax(prediction, axis=1)\n",
    "        if int(predictied_index[0]) == 0:\n",
    "            predictied_index = np.argmin(prediction, axis=1)\n",
    "        score = (prediction[0][predictied_index])\n",
    "        # # print(i, predictied_index)\n",
    "#         print(\"prediction: \", prediction)\n",
    "        score_sum += score\n",
    "        if (i+1)%4==0:\n",
    "            print((score_sum/4)*100)\n",
    "            response = int((score_sum/4)*100)\n",
    "            point_list.append(response)\n",
    "            score_sum=0\n",
    "            name_score+=1\n",
    "    return score_(response)\n",
    "#     return score(response)\n",
    "    ########  回應   ##########\n",
    "# PATH\n",
    "def get_mfcc():\n",
    "    global All_file, file_name\n",
    "    data = {\n",
    "    \"name\":[],\n",
    "    \"labels\": [],\n",
    "    \"mfcc\": []\n",
    "    }\n",
    "    JSON_PATH = \"./audio.json\"\n",
    "    SAMPLE_RATE = 16000\n",
    "    TRACK_DURATION = 10   # measured in seconds   ###### 10 、16秒兩個版本 ######\n",
    "    SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
    "\n",
    "    # PARAMS\n",
    "    num_mfcc=13\n",
    "    n_fft=2048\n",
    "    hop_length=512\n",
    "    num_segments=4\n",
    "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "    \n",
    "#     file = All_file[n]\n",
    "#     All_file[n] = All_file[n].split('\\\\')[-1]\n",
    "#     file_name.append(All_file[n].split('.')[0])\n",
    "    ####  檔案放置路徑, 需要辨識的音檔 ######\n",
    "    # user files transform\n",
    "#     All_file = glob.glob('C:/Users/PC06/Desktop/pikachu training/first_test/*')\n",
    "    file = \"./voice/translate_tts.mp3\"\n",
    "    signal, sample_rate = librosa.load(file, sr=SAMPLE_RATE)\n",
    "\n",
    "    # process all segments of audio file\n",
    "    for id, d in enumerate(range(num_segments)):\n",
    "        # calculate start and finish sample for current segment\n",
    "        start = samples_per_segment * d\n",
    "        finish = start + samples_per_segment\n",
    "\n",
    "        # extract mfcc\n",
    "        mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
    "                                    hop_length=hop_length)\n",
    "#         print(\"-----------------------------\")\n",
    "#         print(\"id\", id+1)\n",
    "#         print(\"mfcc: \", mfcc)\n",
    "#         print(\"-----------------------------\")\n",
    "        \n",
    "#         true_feature = 0\n",
    "#         null_feature = 0\n",
    "#         for n in mfcc[0]:\n",
    "#             if mfcc[0] <=40:\n",
    "                \n",
    "#             else:\n",
    "        mfcc = mfcc.T\n",
    "        mfcc_cut = mfcc.copy()\n",
    "        mfcc_cut[abs(mfcc_cut)<10]=0\n",
    "        # store only mfcc feature with expected number of vectors\n",
    "        if len(mfcc_cut) == num_mfcc_vectors_per_segment:\n",
    "            # print(mfcc)\n",
    "            name = file.split(\".\")[1].split(\".mp3\")[0]\n",
    "            if (id+1)%4 == 0:\n",
    "                data[\"name\"].append(name)\n",
    "            data[\"mfcc\"].append(mfcc.tolist())\n",
    "            data[\"labels\"].append(0)\n",
    "\n",
    "    with open(\"audio.json\", \"w\",encoding=\"utf-8\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "\n",
    "    return file_name\n",
    "\n",
    "## 11/30新增\n",
    "def get_wave_word(file_path):\n",
    "    r = sr.Recognizer()                        #預設辨識英文\n",
    "    with sr.WavFile(file_path) as source:  #讀取wav檔\n",
    "        audio = r.record(source)\n",
    "    try:\n",
    "        return \"Transcription: \" + r.recognize_google(audio,language=\"en\")\n",
    "                                              #使用Google的服務\n",
    "    except LookupError:\n",
    "        return \"請再唸一次\"\n",
    "def check_your_voice_Volume():\n",
    "    normal_sound=0\n",
    "    too_low_sound=0\n",
    "    ## check your talking!!\n",
    "    file_path = \"audio.wav\"\n",
    "    teacher = get_wave_word(\"C:/Users/PC06/Downloads/lili colins/1/Lily Collins Discusses Filming Tolkien and Ted Bundy Biopic This Morning_1.wav\")\n",
    "    student = get_wave_word(file_path)\n",
    "    print(teacher, student)\n",
    "    point = model.wv.similarity(teacher, student)\n",
    "    if point <= 0.8:\n",
    "        return \"妳唸得不太正確, 請在唸一次!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 流程 = 語音接收-->儲存-->mfcc轉換-->判別--回傳結果>\n",
    "if __name__ == '__main__':\n",
    "    TEST_PATH = \"./audio.json\"\n",
    "    check_your_voice_Volume()\n",
    "#     for i,  n in enumerate(range(len(All_file))):\n",
    "    get_mfcc()\n",
    "    # TEST_PATH = \"./json/test_v4.json\"\n",
    "    X, y = load_data_test(TEST_PATH)\n",
    "    # 16s \"Model.h5\" # \"model_version_v7.h5\"\n",
    "    model_load = load_model(\"./model/New 0.341 - 0.9212.h5\")\n",
    "    response = prediction(X, model_load)\n",
    "    print(file_name[i], response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
